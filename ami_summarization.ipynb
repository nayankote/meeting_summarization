{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ami_summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "g3HFI8ElQbDI"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nayankote/meeting_summarization/blob/main/ami_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgD-EBufcVZQ",
        "outputId": "f6d44c38-a690-4638-ddb6-88bb8b047752"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zHNOyZklRvcc"
      },
      "source": [
        "# Installing stuff"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7rT7_vylh39"
      },
      "source": [
        "!pip install pytextrank\n",
        "!python3 -m pip install pytextrank\n",
        "!python3 -m spacy download en_core_web_sm\n",
        "!pip install gensim\n",
        "!pip install transformers datasets rouge-score nltk\n",
        "!pip3 install sentencepiece"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YU7pXo9GR3uK"
      },
      "source": [
        "# Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hr3viPZ4NQwg"
      },
      "source": [
        "**Download ami data from here**  \n",
        "https://drive.google.com/file/d/1e87oOSDPdFwCGSh6-HHn63j0GSpgND5r/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l38vXr5cL1js"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MG-pin4aMN1l",
        "outputId": "754d9eb9-224f-4b68-9584-02da461393e3"
      },
      "source": [
        "!tar -xzvf \"/content/drive/MyDrive/Colab Notebooks/nvidia_task/ami.tar\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ami/\n",
            "ami/test.source\n",
            "ami/val.source\n",
            "ami/train.target\n",
            "ami/test.target\n",
            "ami/val.target\n",
            "ami/train.source\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmS6d0nVMkR2"
      },
      "source": [
        "train = pd.DataFrame({\"source\" : open(\"/content/ami/train.source\",'r').readlines(), \"target\" : open(\"/content/ami/train.target\",'r').readlines()})\n",
        "val = pd.DataFrame({\"source\" : open(\"/content/ami/val.source\",'r').readlines(), \"target\" : open(\"/content/ami/val.target\",'r').readlines()})\n",
        "test = pd.DataFrame({\"source\" : open(\"/content/ami/test.source\",'r').readlines(), \"target\" : open(\"/content/ami/test.target\",'r').readlines()})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZHNBjSPoP8G"
      },
      "source": [
        "Getting train, val and test stats"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3X7_H2ZdM5R6",
        "outputId": "c1bebe26-d42f-42e1-fe5b-159ca5193c7e"
      },
      "source": [
        "len(train), len(val), len(test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 17, 20)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nIh1W9DM6qG",
        "outputId": "df7a59de-1d56-4356-b1e9-1b744b00a3af"
      },
      "source": [
        "train['source_length'] = train['source'].apply(lambda x : len(x.split()))\n",
        "train['target_length'] = train['target'].apply(lambda x : len(x.split()))\n",
        "val['source_length'] = val['source'].apply(lambda x : len(x.split()))\n",
        "val['target_length'] = val['target'].apply(lambda x : len(x.split()))\n",
        "test['source_length'] = test['source'].apply(lambda x : len(x.split()))\n",
        "test['target_length'] = test['target'].apply(lambda x : len(x.split()))\n",
        "print(train['source_length'].describe(), train['target_length'].describe(), val['source_length'].describe(), val['target_length'].describe(), test['source_length'].describe(), test['target_length'].describe(), sep='\\n')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count     105.000000\n",
            "mean     5012.247619\n",
            "std      1992.087071\n",
            "min       747.000000\n",
            "25%      3366.000000\n",
            "50%      5188.000000\n",
            "75%      6549.000000\n",
            "max      9113.000000\n",
            "Name: source_length, dtype: float64\n",
            "count    105.00000\n",
            "mean     164.60000\n",
            "std       49.73963\n",
            "min       78.00000\n",
            "25%      138.00000\n",
            "50%      169.00000\n",
            "75%      192.00000\n",
            "max      530.00000\n",
            "Name: target_length, dtype: float64\n",
            "count      17.000000\n",
            "mean     4921.058824\n",
            "std      1944.404551\n",
            "min      1489.000000\n",
            "25%      2726.000000\n",
            "50%      4868.000000\n",
            "75%      6685.000000\n",
            "max      7518.000000\n",
            "Name: source_length, dtype: float64\n",
            "count     17.000000\n",
            "mean     149.529412\n",
            "std       50.943741\n",
            "min       41.000000\n",
            "25%      131.000000\n",
            "50%      175.000000\n",
            "75%      188.000000\n",
            "max      200.000000\n",
            "Name: target_length, dtype: float64\n",
            "count      20.000000\n",
            "mean     4833.350000\n",
            "std      2124.942087\n",
            "min      1614.000000\n",
            "25%      3158.000000\n",
            "50%      4889.000000\n",
            "75%      6041.250000\n",
            "max      9625.000000\n",
            "Name: source_length, dtype: float64\n",
            "count     20.00000\n",
            "mean     155.50000\n",
            "std       30.84682\n",
            "min      106.00000\n",
            "25%      131.75000\n",
            "50%      157.50000\n",
            "75%      188.50000\n",
            "max      201.00000\n",
            "Name: target_length, dtype: float64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "emkvamu4lYVr",
        "outputId": "110de037-becf-4393-bfa7-53981d98d3af"
      },
      "source": [
        "# an example of the source sentences\n",
        "train['source'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"No. Mm no. Um 'kay um yeah. uh some uh research uh a about um designing of an interface. Um the uh last meeting uh we had a about um uh using a f few buttons. So uh um uh that's w what I what I want to uh uh to do in uh our design. So um finding an attractive uh way to control uh the remote control. Um the uh I found some uh something about uh speech uh recognition. So maybe uh we can uh use uh that. Um Uh and uh using a little uh display. So um findings. Um yeah just um we have just to focus on the primary um functions. So uh only uh buttons uh for uh sound, um for uh on-off, um uh shifting u up uh sa uh ca channel or uh down shifting down. Um uh let's see. Um yeah and Uh we uh need some uh new a attractive functions uh uh which attract uh uh people for using it. So uh it's uh like a speak uh speech uh recognition and um a special button for selecting uh subtitles. Just uh what we uh mentioned uh last uh meeting. Um and yeah overall um user-friendly. So uh using uh large large buttons. Um It's uh possible to uh uh to make um quite cheap uh system for uh speech uh recognition. Um you can think about um uh when you lost your um remote control, you can uh call it and um it gives an um sig signal. So uh uh yeah. And and uh for uh shifting up a sen uh c ch channel or uh for um uh putting out uh sound or something, you can uh just give a sign uh say um sound off or A and uh yeah. Television uh put the sound off uh put the sound off uh. Um Let's see. Uh yeah. I was thinking about the special uh button for uh subtitles, um just one button to keep it uh simple. Uh one push on the button uh you get uh uh small uh subtitles. Um double push push um, if double click, um so uh you get uh big uh subtitles, for uh people uh um uh which c f uh who can't uh read small uh subtitles. So uh Um Yeah and w we have to keep uh in general buttons uh so um we've got um the buttons we have to use. The on-off, sound on-off, sound higher or lower, um the numbers, uh zero to uh uh nine. Um the general buttons m more general b one button for shifting up and shifting down uh channel. Um also we want to uh use a little d display uh for um for displaying the uh the functions of the buttons. And um we can uh build in a function f which uh shows the channel or some uh which the t television is on. So um made a little uh picture of uh it. Um See. Um yeah. Just um we can put uh the on-off button uh over in this uh corner, um almost uh e all uh remote controls uh are using a on-off button on that place. Um so uh people uh will uh recognise uh um the button. So um D display uh of it, it's uh just a small display. Uh um you can put it uh on top. Um it's uh most uh uh place where people uh, most of looks at. So uh um and a special uh button for shifting up uh and uh shifting down uh channel, um it's uh on place where um the thumb of of the So you you can uh easily uh shift up or shift down. Um it's uh quite uh handy place. So um and uh all the f functions for subtitle uh one button, uh for sound uh Uh and uh for our design, um uh we have to discuss about it uh I think uh so uh the form of it so And that's it. Mm. Nah. But what's the function? Yeah f for loading up uh the batteries. B b Okay but uh it won't use uh much e energy uh I I believe. Uh it's uh just a small display so I believe uh it will run on one battery for um six months or f or or more. So I believe one battery uh is just enough. Uh so Okay. Yeah. That's true. Yeah. Mm-hmm. Yeah. Okay. Yeah. Uh. Mm. Mm. 'Kay. Yeah. But uh is uh our uh research um about um bi large uh L_C_D_ sh uh display, or uh just a small one uh we want to uh use? Okay. Yeah. No. Yeah. Yeah. Mm-hmm. Yeah. Uh I dunno. Mm. Mm. Uh is it possible uh to make um changeable uh case. So um uh you 'cause uh Yeah with uh mobile phones uh uh so uh like the Nokia mobile phones, uh when you can change the case of it. So maybe it's possible uh possibility. So um um you have just to make one um standard um remote control, and um yeah you can sell uh few uh Yeah. Yeah. Yeah. Yeah. Yeah. okay. Mm. Uh we can just use the regular form of it, but it's um not quite uh fancy. So um Yeah. Yeah. Yeah. For uh Uh for Yeah yeah. Mm. Yeah we um Is it possible to um program it s so uh you got on the left side uh or on the right side uh buttons for for shifting u up and shifting up? And on the uh other uh uh o other side uh buttons for uh shifting, uh for for the sound? Or Or isn't it? Yeah okay. Uh. Mm. Yeah but Yeah. Yeah. Yeah. See um yeah. Or we have to make a left uh For lefties and Um You mean um Yeah if Mm no. Yeah. Um Yeah. It's just uh u using uh your thumb. So um it's Yeah. Yeah. Um Yeah yeah. Mm-hmm. Mm. So um Do you say this um S uh Uh you got like uh sort of a I believe There? So um you want to put a display over here? Or not? Yeah. Um Yeah. Uh we can make it um Mm? That's the top. So uh this top. This down. Um maybe it's possible to uh make this side like um Let's see. Um Colour uh okay. Uh to make this side um like mm the right colour. Um bit like so uh um in the form of your hand. So um Uh it's an So so the remote control have to um lay in your hand. So uh it's possib um yeah for s so and And to put uh the the buttons for um changing uh the channel uh over here uh Yeah. Uh rem Yeah but this place um Uh it's Yeah I dunno um Yeah. Yeah so So Five minutes. Yeah. Yeah. But um the on-off button, um still on the top uh Yeah. Yeah. Yeah. 'Kay. Yeah. Yeah. Yeah. Okay. Good afternoon. Sure. I'll start off then. Doh. 'Kay I'm uh gonna inform you about the trend-watching I've done over the past few days. Um we've done some market research. We distributed some more enquetes, questionnaires. And um besides that um I deployed some trend-watchers to Milan and Paris to well get all of the newest trends. And I've consulted some additional trend-watch trend-watchers, after the original trend-watchers return, about what the the best design would be. Um okay these are some overall findings. Um most important thing is the fancy design. Um the research indicated that that was by far the most important factor. Um innovativeness was about half as important as the fancy design. By innovativeness this means um functions which are not featured in other remote controls. Um about half of, half as important as the innovativeness was the was easy to use. Um for our um group, we're focusing on the people of sixty to eighty y years old, this is um, these factors are slightly more equal. 'Kay these are some more group specific findings. Uh the older people prefer dark colours. Uh they like recognisable shapes, and familiar material. And our surveys have indicated that especially wood is pretty much the material for older people. Um this is, this image will give you a little bit of an impression about um the look-and-feel that um the remote should have. Um this leads us to some personal preferences. Uh the remote control and the docking station should uh blend in in the in the room. Um so this would mean no uh eye-catching designs. Just keep it simple and Well the docking station and small screen would be our main points of interest, because this would be the These would uh be the innovativeness in the remote control. So this would be very important that we at least include these features. Um well the trend-watchers I consulted advised that it b should be, the remote control and the docking station should be telephone-shaped. So you could imagine that uh the remote control will be standing up straight in the docking station. This is not really This is pretty much a new shape to uh older people. So they would prefer uh a design where the remote control just lies flat in the docking station. So it would be kinda more telephone-shaped. Um besides that we would advise um to bring two editions, one with a wood-like colour and maybe feel, and one with a grey-black colour. The wood-like for the more uh exclusive people. People with more money. Uh the grey-black colour for well people with less means. That would be all. Any questions? And how exactly does the kinetic energy work? You just You use it and it works. Okay. Well personally I don't think that older people like to shake their remote control before they use it. And besides that you mentioned it would make the docking station obsolete. And I think our docking station could be one of the marketing issues with which we can um get great popularity for our product. Um wel Yeah you could load up the batteries, you could um insert the find the lost remote control function in there. That's true. I'm wondering um what will the voice recognition mean for the production price? 'Cause in our earlier um market research, if you'd allow me to go to the flat board, SMARTboard. Um so it was open here. Um we also um asked if w they would, if people would pay more for speech recognition in a remote control. Well you can see here, our target group would not do that. So if that would increase the price for which we're selling our remote control I would greatly advise not to do it. I think that would be better to uh insert in our other product, that is meant for the younger people. Um well this is Yeah but this is here the question was, would you prefer it. So that doesn't really mean they wouldn't pay extra for it. And on top of that the L_C_D_ screen would um help in making the remote control easier to use. And I think a voice recognition function would not make the remote control much easier to use. Um well this was for like an L_C_D_ screen like you would have on a on the the most advanced mobile phones. So pretty large. 'Kay. Mm-hmm. Mm-hmm. Well And I think most important factor there is the wooden colour. So it wouldn't actually have to be wood, if it's just wood-coloured. Probably. Yeah that is true. Yeah. We would have to look carefully into the design though. 'Cause we would have to make one w uh control which would fit in with a wooden cover and a plastic cover. The more original one, or the more standard one. So that would Well I wouldn't design a telephone but Well no I think w we should just, we should then just design one um one remote, but it would have to be fancy with either the wood cover or the plastic one. So, but that shouldn't be too much of a problem. Um I heard our Industrial Designer talk about uh flat, single and double curved. Could you explain that a little more? Mm-hmm. And what would single curved and double curved mean? Okay. So we can pretty much just do whatever we want. 'Kay. That's good. No just to lie down. We'll go for that. Well or besides it. Mm-hmm. Um you uh said you wanted to put the um changing channels button on the right side, so you could, so your thumb would be easily Well uh I think that was a very good point 'cause I pointed out earlier that a lot of remotes cause R_S_I_. So that would be great for that. Um I thought maybe we could just make one of those buttons on both the left and the right side. For left-handed users also. For the volume. Um well that could Yeah we could do that but I'm not sure if that would be very good for the easy, ease of use. But if we would make um a changing channels and changing volume button on both sides, that would certainly yield great options for the design of the remote. 'Cause it could be made all symmetrical and stuff. That is true. Yeah. Yeah. That is true. Yeah. Mm-hmm. Mm. Mm-hmm. Mm-hmm. Yeah. Yeah. Mm-hmm. And I'd prefer the corners to be round. Think that would be better. Friendly on the eye. Yeah. Yeah. Very good. Okay. About the components design. Um for the energy source we can use a basic battery or, a as an optional thing, a kinetic energy, like in a watch, which you just shake and it produces energy. But if we choose for that option, the docking station would c become obsolete. So I don't think it's really an option. Uh for the casing, uh the uh manufacturing department can deliver uh a flat casing, single or double curved casing. It's really up the the design that we're gonna use. It's uh doesn't uh imply any technical restrictions. Uh as a case supplement, we could um, I thought of that l later, uh a rubber uh belt, like a anti-slip. Uh for the b buttons, we can use plastic or rubber. And the chip-set, um it says simple here, but it should be advanced, because we're using an L_C_D_ uh screen. And as uh the trend-watcher presentation showed, um people like wood, but it raises the price and it doesn't really fit the image, unless we would start two product lines. Form should follow function overall. Um well the kinetic energy source is rather fancy. But depends on what we want. I think we should disc discuss that. Um for the case, uh the supplement and the buttons, it really depends on the designer. And the chip-set uh really should be advanced because otherwise uh it would really be a simple uh remote control. And that's it. Yes w there there are four options. We could use the basic normal battery. Uh a hand dynamo. But I don't think that's really an option. You don't wanna swing before you can watch television. Uh solar cells. But not every room is very light so it's not a very good option. Or the kinetic energy. Well y you basically shake your remote, and then it powers up. Yeah. Yeah. That's true. Oh. Mm I don't have any information on pricing. So I'll have to ask the manufacturing department. But that would also go for the L_C_D_ screen then I guess. It's a bit higher percentage, but Okay. And that's the best choice. Well there isn't any choice there because we're using the the the the display. So it's gotta be advanced. Mm I dunno. I'll have to uh research. Yes. Yes. Well the the general like most older remotes are flat, just straight. And uh our d manufacturing department can also deliver single curved or double curved ca curved cases. Um it would just only affect the form, for as far as I know. So it's j really just up to the design department what we're gonna use. It doesn't really matter for the price or the functionality. Pick one you like, yes. Yeah. I think we should start by by choosing a case. Because that's the basis you're building on. So I could draw them out. Let's look at the flat case. Oh. It's from the side so it's rather normal. The the single curved so I'm not really sure what they're gonna look like, but I think it's something like this. So this type should be better for you or better Should prevent repetitive strain injury a bit. And the double curved s looks something like this I guess. So th those are the three options we have. Yeah. It's more logical to have it on top as well because, like on your mobile phone, it's always above. Oh maybe you should just s start on a blank page. Okay. Okay. Okay. Uh good afternoon. This is our third meeting already. I hope you enjoyed your lunch. I did anyway. Um let's see. Presentation three. Okay this is um the second phase uh we're going to discuss today. It's the conceptual design meeting. And a few points of interest in this meeting um are the conceptual specification of components. Uh conceptual specification of design. And also trend-watching. Um these are hopefully the points you addressed in uh your pre uh presentations you're going to show me in a few minutes. Um but first I'll show you the agenda. Uh first the opening. Then we have three presentations. Uh after that we have to come to a decision on remote control concepts. How we're going to make it. And then we're closing. We have about forty minutes. Uh so I suggest let's get started. Uh did someone encounter any problems during the preparation? No? Everything fine? That's nice. Then a little uh thing about the last meeting. Uh these are the points um we agreed on. The requirements and the target market. Uh requirements are uh teletext, docking station, audio signal, small screen, with some extras that uh button information. And we are going to use default materials. Um does somebody have any comments on these requirements? Maybe? No? These are just the the things we thought of, so maybe if you figured something else or thought of something else, just let me know. And maybe we can uh work it out. And we're going to target uh sixty to to eighty year old customers. So now everybody knows what we're do we're doing, um I suggest let's get started with the presentations. So shall we keep the same uh line-up as uh last time? Okay. Good luck. Okay. Thank you. Any questions about the the trends? Mayb No? Okay, we go on to the next one. Okay. Uh thank you. Okay. Thank you. So that brings us to the discussion about our concepts. Mm. 'Kay. So these are the points we have to discuss. Um first I think we can talk about the energy source, since that's um has a pretty big influence on production price, uh and image. Uh so uh f I think first of all we have to see uh it is possible to introduce kinetic energy in our budget, I think. Yeah. Okay. Yeah. No. Yeah. Okay. Yeah. Yeah. Uh Uh well I think uh elderly people just like to have everything in place. And I don't think they they like uh remotes just laying everywhere in their rooms. So maybe a docking station will help them give the remote a place. And also what you said. Um you can introduce voice recognition by uh finding back your remote. But I think it's um more efficient and cheaper to put it in the docking station. So you have a but button on your docking station which you can push, and then it starts beeping. And then we can we can still use the voice recognition, but maybe then for only the the channels. That's safe. Yeah. That's a good point. Yeah, sure. Go ahead. No. Yeah. Yeah. Yeah. Easier to use? No, I think that's a good point. Yeah. I personally think the L_C_D_ screen we wanna use, with the extra information, I think nobody has anything against it. Because it's just uh some extra information, and it's easy to ignore as well. So if you don't wanna use it you just don't use it. And um yeah I think the um Maybe we have to uh discard the voice recognition. Because it will increase cost uh signifi uh significantly. And I don't think the I don't think it will be a lot easier to use, as well. So that brings us back to the energy. If we don't have the voice recognition, it will it won't use a lot of energy to use. Um So in that case we could use kinetic uh energy, but I think just a simple battery which you can reload on a docking station is just as good. And much cheaper as well. So Okay let me just choose for the battery. That brings us to the chip. Just the advanced. Okay, advanced chip. And then we get to the point of the case. Um which brings us a little bit back to marketing as well. Uh if we wanna choose for wood or the black and grey. Or both? Um as we saw there is not Yeah wood is a lot more expensive to produce. Um but I think it will attract elderly people who wanna have something exclusive, which they can show off to their grandkids. Look I've got a new remote control, and uh Yeah. That's right. But with colour was a lot more expensive? Or? You don't know? I think so because Yeah. It's a lot more difficult to to handle and to to get in the right shape. Yeah. Change the cases. Yeah. You can sell the cases. Yeah. I think that's a very good option. Because um then you can advertise as well with the Give your grandfather a new case for his remote control, or whatever. Because that's a it's something extra, it's something other remotes don't have, which we can get a great advantage point. So and then you can make them with colour. Black and grey, other colours as well. Costs. Yeah. Yeah. So you suggest we should design two different telephones on which you can apply, yeah remote controls, on which you can apply different case covers, for example. Remote. Yeah. Okay. So everybody's okay with the changing covers? I think that's a good uh good option. Changing case covers. Yeah. Mm. Okay. Uh but the form has to be um It has to It's has to be possible to stand up? Or just only to lie down? And the the cover of the the docking station is also on top of the television then? Or not? And you can just yeah then click it in. That's okay. Um so the interface. What type of interface do we want to use? Um maybe you can make a little drawing of it on the on the the board. Does somebody have ideas for a form or Yep. Mm. Usabili Yeah ease of use will be a lot more difficult, and then it's But you have extra buttons. So people can get confused. Especially if they have the same writings on it. Can't we make uh Can't we make a remote which you can flip over and use on the same functions as the normal one? Then you have to Let's see if I ca A blank one. And then you get Here's a little L_C_D_ screen. Uh now I have to think. It's a plus and a min. No it's not very handy I think. Because the plus and the min will be opposite and all kinds of No that's not gonna work. I guess. Maybe we should Yeah. But is it a problem that left-handed persons use a different hand? I think the functions are that basic that nobody should have any problems with uh choosing a channel or Y yeah. Yeah. I think we could just uh leave it a normal shape. Uh but maybe we have to make it a l a bit more fancy. In one or ano another way. Yeah. Um yeah just Yeah. Easier? 'Kay. I suggest um the single curved, because maybe the curve is pretty good to put the the screen in. Uh so that elderly people can uh use the remote control and at the same time look easily at the screen, because it's a bit, it has a bit of a angle. Yeah. I think so. Yeah. But now it's Do you have it upside down or Do you have it this that's top? Okay. Yeah. So get your mouse. Yeah. Yeah. That's a good one. But I think it's better to put the screen uh on top. So just flip it a hundred and eighty degrees around then you get here. If you can have this one, you turn it like this. And then flip it upside down. Because uh maybe your hand is in the way, if you have the display here. I think i On top. Yeah.. So then we get Here's That's the curve. Here the display, and then buttons. Yeah and then we can have a little bit off here and here maybe. Just that's for left hand and right hand users. And then h the rest of the buttons over here. Yeah still here jus That's Yeah. Should be more bit more friendly, yeah. 'Kay. Supplements. That's okay. Where's my mouse? Then We've got a general idea of the concepts and the materials we're going to use. So now for the next meeting uh we'll have to look at the look-and-feel design. It's important that the corporate design image uh is going to be in the remote. So check out the corporate website maybe. The user interface design, it's the same story. And product evaluation. So the Industrial Designer and User Interface Designer are going to work together on this one. But you're going to get your instructions I think sended by the coach. So just um I will put these um minutes on the in the folder. And then we're going to uh try to finish our project, and uh make a good design for all the grandfathers and grandmothers, I think. Which are Uh let's see. I'm not sure if you're going to start right away to work together or I think you're going to fill in the questionnaires first. And then you'll get a message. So that's uh basically it. Maybe this one? Then we can save this one in the folders group. Uh yes, it's here. SMARTboard, there it it. So if you wanna have a look at it, it's over there in the projects folder. And then I guess we'll start in thirty minutes again. Thank you.\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VN653q5zNkMV"
      },
      "source": [
        "# Extractive Summarization\n",
        "\n",
        "The input transcripts to be summarized are extremely large, with a mean of roughly 5012 words. Most open source summarization models like t5, bart and pegasus have a maximum token length of 512 or 1024 tokens. Hence it is important to have an extractive step to obtain the most information rich sentences from the large corpus to prevent loss of information due to truncation during tokenization. For this extractive step it is sufficient to use a pagerank type algorithm such as the ones in pytextrank or gensim. In the final pipeline I have used gensim as the output preserved sentence order and was more readable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3HFI8ElQbDI"
      },
      "source": [
        "# Using pytextrank"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYNu0dcrSrt-"
      },
      "source": [
        "import spacy\n",
        "import pytextrank\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def clean_text(text):\n",
        "  cleaned_lines = []\n",
        "  forbidden_list = [\"\\n\", \"um\", \"uh\", \"hmm\", \"mm-hmm\", \"mm\", \"oops\", \"'kay\", \"yeah\"]\n",
        "  for text in text.lower().split(\".\"):\n",
        "    text = text.strip()\n",
        "    for w in forbidden_list : text = text.replace(w,\"\")\n",
        "    words = []\n",
        "    for word in text.split(\" \"):\n",
        "      if len(word) <= 1 and word not in ['a','i'] : continue\n",
        "      else : words.append(word)\n",
        "    if len(words)>2 : cleaned_lines.append(\" \".join(words).strip())\n",
        "\n",
        "  return \". \".join(cleaned_lines)\n",
        "\n",
        "def get_sentences(text):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(text)\n",
        "    try : \n",
        "        nlp.add_pipe(\"textrank\")\n",
        "    except: \n",
        "        pass\n",
        "    doc = nlp(text)\n",
        "\n",
        "    final_sentence = \"\"\n",
        "    len_sentence = 0\n",
        "    for sent in doc._.textrank.summary(limit_phrases=100, limit_sentences=200, preserve_order=False):\n",
        "        final_sentence += str(sent) + \" \"\n",
        "        len_sentence += len(str(sent).split(\" \"))\n",
        "        if len_sentence >= 1024 : break\n",
        "    return final_sentence.strip(\" \")\n",
        "\n",
        "#train['source_final_1'] = train['source'].apply(lambda x :get_sentences(clean_text(x)))\n",
        "#val['source_final_1'] = val['source'].apply(lambda x : get_sentences(clean_text(x)))\n",
        "#test['source_final_1'] = test['source'].apply(lambda x : get_sentences(clean_text(x)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHCznQ6meqqR"
      },
      "source": [
        "# Using gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDE7i1SaPphm"
      },
      "source": [
        "**Text cleaning**  \n",
        "Since the input data is conversational, there is a lot of affirmations, repetitions and stutters represented by individual letters. These have to be cleaned and clean_text does that. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF2yT7spe3H3"
      },
      "source": [
        "from gensim.summarization import summarize\n",
        "\n",
        "def clean_text(text):\n",
        "  cleaned_lines = []\n",
        "  forbidden_list = [\"\\n\", \"um\", \"uh\", \"hmm\", \"mm-hmm\", \"mm\", \"oops\", \"'kay\", \"yeah\"]\n",
        "  for text in text.lower().split(\".\"):\n",
        "    text = text.strip()\n",
        "    for w in forbidden_list : text = text.replace(w,\"\")\n",
        "    words = []\n",
        "    for word in text.split(\" \"):\n",
        "      if len(word) <= 1 and word not in ['a','i'] : continue\n",
        "      else : words.append(word)\n",
        "    if len(words)>2 : cleaned_lines.append(\" \".join(words).strip())\n",
        "\n",
        "  return \". \".join(cleaned_lines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BARNWmogftez"
      },
      "source": [
        "train['source_final'] = train['source'].apply(lambda x : \" \".join(summarize(clean_text(x), word_count=1024, split=True)))\n",
        "val['source_final'] = val['source'].apply(lambda x : \" \".join(summarize(clean_text(x), word_count=1024, split=True)))\n",
        "test['source_final'] = test['source'].apply(lambda x : \" \".join(summarize(clean_text(x), word_count=1024, split=True)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ZRLwLAxTguXP",
        "outputId": "b1a0ff68-dba4-4a41-8a83-11c81608d1bf"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>source_length</th>\n",
              "      <th>target_length</th>\n",
              "      <th>source_final</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>No. Mm no. Um 'kay um yeah. uh some uh researc...</td>\n",
              "      <td>The project manager opened the meeting and rec...</td>\n",
              "      <td>4588</td>\n",
              "      <td>131</td>\n",
              "      <td>so it's like a speak speech recognition and a ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What? Yeah. Yeah. We didn't make any uh Oh in ...</td>\n",
              "      <td>The project manager opened the meeting and the...</td>\n",
              "      <td>9113</td>\n",
              "      <td>150</td>\n",
              "      <td>you push the scroll button and it's claps out ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Okay. B you think uh I I'm User Interface Mana...</td>\n",
              "      <td>The project manager opened the meeting and the...</td>\n",
              "      <td>5188</td>\n",
              "      <td>97</td>\n",
              "      <td>okay, about what i found about different these...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yep. Um So hello everybody. So uh you everybod...</td>\n",
              "      <td>When the meeting opens the project manager giv...</td>\n",
              "      <td>7532</td>\n",
              "      <td>87</td>\n",
              "      <td>so the goal for today is to decide for a movie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>You could change the vegetable, or fruit. Yeah...</td>\n",
              "      <td>The Project Manager reviewed the minutes from ...</td>\n",
              "      <td>4516</td>\n",
              "      <td>181</td>\n",
              "      <td>it's been a it's been a little bit difficult t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              source  ...                                       source_final\n",
              "0  No. Mm no. Um 'kay um yeah. uh some uh researc...  ...  so it's like a speak speech recognition and a ...\n",
              "1  What? Yeah. Yeah. We didn't make any uh Oh in ...  ...  you push the scroll button and it's claps out ...\n",
              "2  Okay. B you think uh I I'm User Interface Mana...  ...  okay, about what i found about different these...\n",
              "3  Yep. Um So hello everybody. So uh you everybod...  ...  so the goal for today is to decide for a movie...\n",
              "4  You could change the vegetable, or fruit. Yeah...  ...  it's been a it's been a little bit difficult t...\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "6t8lgarI-BaE",
        "outputId": "333f59fe-006d-42e8-d2ec-8f95dbe63bd8"
      },
      "source": [
        "\"\"\"\n",
        "train.to_csv(\"/content/drive/MyDrive/Colab Notebooks/nvidia_task/train_processed.csv\")\n",
        "val.to_csv(\"/content/drive/MyDrive/Colab Notebooks/nvidia_task/val_processed.csv\")\n",
        "test.to_csv(\"/content/drive/MyDrive/Colab Notebooks/nvidia_task/test_processed.csv\")\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\ntrain.to_csv(\"/content/drive/MyDrive/Colab Notebooks/nvidia_task/train_processed.csv\")\\nval.to_csv(\"/content/drive/MyDrive/Colab Notebooks/nvidia_task/val_processed.csv\")\\ntest.to_csv(\"/content/drive/MyDrive/Colab Notebooks/nvidia_task/test_processed.csv\")\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZNO83ryhMq5"
      },
      "source": [
        "# Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQBH4nM-SZyb"
      },
      "source": [
        "**Abstractive summarization**  \n",
        "3 of the best scoring models from huggingface will be tried, i.e. t5, bart and pegasus. Their corresponding tokenizers will be used to vectorize the input text. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VGgCzGRbZZmX",
        "outputId": "0523b4c9-2e80-4c49-a26d-b77346ff8d71"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue May 18 17:24:42 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     8W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9I5xNafT54iT",
        "outputId": "312b30d2-543b-4b43-9598-746a0422909b"
      },
      "source": [
        "import nltk\n",
        "import numpy as np\n",
        "import random\n",
        "nltk.download('punkt')\n",
        "from datasets import load_metric\n",
        "\n",
        "metric = load_metric('rouge')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IUEJUa7OJJr"
      },
      "source": [
        "import torch\n",
        "import transformers\n",
        "from transformers import AutoTokenizer\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoModelForSeq2SeqLM, DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g9EYx_VBO30Z",
        "outputId": "b13a8641-8112-4415-99ba-404f072bbd16"
      },
      "source": [
        "model_checkpoint = \"facebook/bart-large\"\n",
        "prefix = \"summarize: \" if \"t5\" in model_checkpoint else \"\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint) #.task_specific_params['summarization']\n",
        "\n",
        "max_input_length = 1024\n",
        "max_target_length = 256\n",
        "\n",
        "def tokenize_sentences(data):\n",
        "  inputs = [prefix + text for text in data['source_final']]\n",
        "  labels = [target for target in data['target']]\n",
        "  tokenized_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True, padding=True, add_special_tokens=True) # , return_tensors='pt'\n",
        "\n",
        "  with tokenizer.as_target_tokenizer():\n",
        "    labels = tokenizer(labels, max_length=max_target_length, padding=True, truncation=True, add_special_tokens=True) # , return_tensors='pt'\n",
        "\n",
        "  model_inputs = {\"input_ids\" : tokenized_inputs['input_ids'], \"attention_mask\" : tokenized_inputs['attention_mask'], \"decoder_attention_mask\" : labels['attention_mask'], \"labels\" : labels['input_ids']}\n",
        "  return model_inputs\n",
        "\n",
        "train_tokenized = tokenize_sentences(train)\n",
        "val_tokenized = tokenize_sentences(val)\n",
        "test_tokenized = tokenize_sentences(test)\n",
        "train_tokenized.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'decoder_attention_mask', 'labels'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9lHS0mQXDYy"
      },
      "source": [
        "class AMIDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self,encodings):\n",
        "    super(AMIDataset, self).__init__()\n",
        "    self.encodings=encodings\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    #return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "    return {key: val[idx] for key, val in self.encodings.items()}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.encodings['input_ids'])\n",
        "\n",
        "train_dataset = AMIDataset(train_tokenized)\n",
        "val_dataset = AMIDataset(val_tokenized)\n",
        "test_dataset = AMIDataset(test_tokenized)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClFNyE6nhp_6"
      },
      "source": [
        "if \"bart\" in model_checkpoint:\n",
        "  for i, batch in enumerate(train_dataset):\n",
        "    if 2 not in batch['input_ids'] and 2 not in batch['labels'] : print(i, batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "id": "-nZ8jXN9kArB",
        "outputId": "137a61c6-64f0-475c-bb1f-a7a5db2b59af"
      },
      "source": [
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint) #.task_specific_params['summarization']\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else 'cpu'\n",
        "batch_size = 4\n",
        "args = Seq2SeqTrainingArguments(\n",
        "    \"test-summarization\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    learning_rate=1e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    weight_decay=0.01,\n",
        "    save_total_limit=3,\n",
        "    num_train_epochs=5,\n",
        "    predict_with_generate=True,\n",
        "    fp16=True,\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n",
        "\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    predictions, labels = eval_pred\n",
        "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
        "    # Replace -100 in the labels as we can't decode them.\n",
        "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
        "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
        "    \n",
        "    # Rouge expects a newline after each sentence\n",
        "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
        "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
        "    \n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
        "    # Extract a few results\n",
        "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "    \n",
        "    # Add mean generated length\n",
        "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
        "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
        "    \n",
        "    return {k: round(v, 4) for k, v in result.items()}\n",
        "\n",
        "def freeze_params(model, encoder=True, decoder=False, embedding=True, t5=False):\n",
        "  if t5 : \n",
        "    encoder_params = model.encoder.parameters()\n",
        "    decoder_params = model.decoder.parameters()\n",
        "    embedding_params = model.shared.parameters()\n",
        "  else : \n",
        "    encoder_params = model.model.encoder.parameters()\n",
        "    decoder_params = model.model.decoder.parameters()\n",
        "    embedding_params = model.model.shared.parameters()\n",
        "  if encoder : \n",
        "    for param in encoder_params:\n",
        "      param.requires_grad = False\n",
        "\n",
        "  if decoder : \n",
        "    for param in decoder_params:\n",
        "      param.requires_grad = False\n",
        "\n",
        "  if embedding : \n",
        "    for param in embedding_params:\n",
        "      param.requires_grad = False\n",
        "\n",
        "freeze_params(model,encoder=True,decoder=False,embedding=False,t5 = \"t5\" in model_checkpoint)\n",
        "\n",
        "trainer = Seq2SeqTrainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='135' max='135' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [135/135 03:03, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rouge1</th>\n",
              "      <th>Rouge2</th>\n",
              "      <th>Rougel</th>\n",
              "      <th>Rougelsum</th>\n",
              "      <th>Gen Len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>6.038740</td>\n",
              "      <td>8.486600</td>\n",
              "      <td>1.490500</td>\n",
              "      <td>6.538600</td>\n",
              "      <td>7.651500</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>5.334928</td>\n",
              "      <td>15.620300</td>\n",
              "      <td>7.190900</td>\n",
              "      <td>13.652600</td>\n",
              "      <td>14.895400</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.798257</td>\n",
              "      <td>15.404700</td>\n",
              "      <td>6.905400</td>\n",
              "      <td>13.114600</td>\n",
              "      <td>14.363300</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.405800</td>\n",
              "      <td>15.782800</td>\n",
              "      <td>6.898700</td>\n",
              "      <td>13.475200</td>\n",
              "      <td>14.575800</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>4.325643</td>\n",
              "      <td>15.750900</td>\n",
              "      <td>7.149100</td>\n",
              "      <td>13.566600</td>\n",
              "      <td>14.492300</td>\n",
              "      <td>20.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=135, training_loss=5.189368127893519, metrics={'train_runtime': 184.1857, 'train_samples_per_second': 0.733, 'total_flos': 1638167150592000.0, 'epoch': 5.0, 'init_mem_cpu_alloc_delta': 4096, 'init_mem_gpu_alloc_delta': 1625367040, 'init_mem_cpu_peaked_delta': 0, 'init_mem_gpu_peaked_delta': 0, 'train_mem_cpu_alloc_delta': 638976, 'train_mem_gpu_alloc_delta': 2431385088, 'train_mem_cpu_peaked_delta': 61440, 'train_mem_gpu_peaked_delta': 5273206272})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLCGOUnUu0x-"
      },
      "source": [
        "def quick_test(model,device,dataset,idx=-1,tensor=False):\n",
        "  if idx == -1 : \n",
        "    idx = random.randint(0,len(dataset))\n",
        "    print(idx)\n",
        "  if tensor:\n",
        "    print(\"input is tensor\")\n",
        "    decoded = tokenizer.decode(model.generate(dataset[idx]['input_ids'].view(1,-1).to(device),min_length = 0, max_length=max_target_length, attention_mask=dataset[idx]['attention_mask'].view(1,-1).to(device))[0], skip_special_tokens=True) #\n",
        "    original = tokenizer.decode(dataset[idx]['labels'].to(device), skip_special_tokens=True)\n",
        "  else : \n",
        "    decoded = tokenizer.decode(model.generate(torch.tensor(dataset[idx]['input_ids']).view(1,-1).to(device),max_length=180, attention_mask=torch.tensor(dataset[idx]['attention_mask']).view(1,-1).to(device), \n",
        "                                              early_stopping = True, no_repeat_ngram_size = 3,  top_p=0.9, top_k=15)[0], skip_special_tokens=True) #  forced_eos_token_id=tokenizer.eos_token_id,\n",
        "    original = tokenizer.decode(torch.tensor(dataset[idx]['labels']).to(device), skip_special_tokens=True)\n",
        "  # removing truncated last sentence : \n",
        "  if decoded[-1]!=\".\" : \n",
        "    decoded = \".\".join(decoded.split(\".\")[:-1]) + \".\"\n",
        "  scores = metric.compute(predictions=[decoded], references=[original], use_stemmer=True)\n",
        "  rouge1, rouge2, rougeL = scores['rouge1'].mid.fmeasure, scores['rouge2'].mid.fmeasure, scores['rougeL'].mid.fmeasure\n",
        "\n",
        "  return decoded, original, rouge1, rouge2, rougeL"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-Y9G_k3jMjV",
        "outputId": "73eb8bc1-1f62-473b-f9c9-21961c4e8440"
      },
      "source": [
        "quick_test(model,device,val_dataset,3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('The project manager opened the meeting by talking about the components that would be used to make the remote. The team discussed the energy source, the design of the case, the buttons, and the face-plates. The project manager discussed the possibility of using kinetic energy to power the device. The user interface designer presented the idea of using a scroll button to control the remote, and suggested that the user interface could be based on a fruit and vegetable theme. The marketing expert presented the use of a graphical user interface, which would include a number of different symbols. The industrial designer presented an idea for a light-up display, which could be incorporated into the design. The group discussed how to make a remote that could be easily reconstituted, and how to incorporate a scroll-button into it. The Project Manager then presented the project budget for the project. The Marketing Expert presented the',\n",
              " \"The project manager opens this conceptual design meeting and gives them the agenda. The industrial designer presents first and talks about the components of a remote, energy source options, and materials for the remote, case, and buttons. The interface specialist presents the interface concept by explaining the difference between graphical and command interface. They decide the command interface is most useful for a remote because it is simpler and more user-friendly. The group discusses aspects of the user interface including the lighting up effect and material of the buttons. The marketing expert presents on trend-watching and talks about how fruit and vegetables are an important fashion theme this year, and says the material used is expected to be spongy. The group discusses how they could implement these fashion trends into the design, then finalizes a few decisions about the components, materials, and energy sources. The project manager closes the meeting, stating what each member's next task will be.\\n\",\n",
              " 0.5615141955835962,\n",
              " 0.2222222222222222,\n",
              " 0.2965299684542586)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8HIxVkmwjLQm",
        "outputId": "dcb9a32f-caf1-428b-a23d-2e51bc4fdec6"
      },
      "source": [
        "test_results = {}\n",
        "for i,batch in enumerate(test_dataset):\n",
        "  decoded, original, rouge1, rouge2, rougeL = quick_test(model,device,test_dataset,i)\n",
        "  test_results[i] = {\"generated\" : decoded, \"original\" : original, \"rouge1\" : rouge1, \"rouge2\" : rouge2, \"rougeL\" : rougeL}\n",
        "\n",
        "test_results = pd.DataFrame(test_results).transpose()\n",
        "print(round(sum(test_results['rouge1'])/len(test_results['rouge1']),4)*100, round(sum(test_results['rouge2'])/len(test_results['rouge2']),4)*100, round(sum(test_results['rougeL'])/len(test_results['rougeL']),4)*100)\n",
        "\n",
        "val_results = {}\n",
        "for i,batch in enumerate(val_dataset):\n",
        "  decoded, original, rouge1, rouge2, rougeL = quick_test(model,device,val_dataset,i)\n",
        "  val_results[i] = {\"generated\" : decoded, \"original\" : original, \"rouge1\" : rouge1, \"rouge2\" : rouge2, \"rougeL\" : rougeL}\n",
        "\n",
        "val_results = pd.DataFrame(val_results).transpose()\n",
        "print(round(sum(val_results['rouge1'])/len(val_results['rouge1']),4)*100, round(sum(val_results['rouge2'])/len(val_results['rouge2']),4)*100, round(sum(val_results['rougeL'])/len(val_results['rougeL']),4)*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "47.28 17.25 26.400000000000002\n",
            "45.79 15.83 24.27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QuMvnd5Igw9"
      },
      "source": [
        "torch.save(model.state_dict(), \"/content/drive/MyDrive/Colab Notebooks/nvidia_task/model_bart_large\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lW9I7LcvPbJ"
      },
      "source": [
        "import json\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/nvidia_task/bart_large_test.json\",'w') as f: json.dump(test_results.to_json(),f)\n",
        "with open(\"/content/drive/MyDrive/Colab Notebooks/nvidia_task/bart_large_val.json\",'w') as f: json.dump(val_results.to_json(),f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "D3afc6aYtUZB",
        "outputId": "da31b32a-87ff-4d0a-8903-c865f6fb7500"
      },
      "source": [
        "with open(\"/content/drive/MyDrive/Colab Notebooks/nvidia_task/bart_large_test.json\",'r') as inf : a = json.load(inf)\n",
        "pd.DataFrame(eval(a))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>generated</th>\n",
              "      <th>original</th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The project manager opened the meeting by goin...</td>\n",
              "      <td>This last meeting started with the presentatio...</td>\n",
              "      <td>0.419453</td>\n",
              "      <td>0.122324</td>\n",
              "      <td>0.200608</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The Project Manager opens the meeting. The Pro...</td>\n",
              "      <td>The project manager opened the meeting and had...</td>\n",
              "      <td>0.426230</td>\n",
              "      <td>0.198347</td>\n",
              "      <td>0.245902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>The project manager opened the meeting by goin...</td>\n",
              "      <td>The Project Manager presented the goals of the...</td>\n",
              "      <td>0.574018</td>\n",
              "      <td>0.297872</td>\n",
              "      <td>0.308157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The project manager opens the meeting by going...</td>\n",
              "      <td>The project manager opened the meeting and sta...</td>\n",
              "      <td>0.479167</td>\n",
              "      <td>0.167832</td>\n",
              "      <td>0.256944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Project Manager opened the meeting by stat...</td>\n",
              "      <td>The Project Manager presented the final cost o...</td>\n",
              "      <td>0.564706</td>\n",
              "      <td>0.252964</td>\n",
              "      <td>0.313725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The project manager opened the meeting by goin...</td>\n",
              "      <td>For the conceptual design, the ID suggested to...</td>\n",
              "      <td>0.449568</td>\n",
              "      <td>0.127536</td>\n",
              "      <td>0.190202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>The Project Manager opened the meeting by reca...</td>\n",
              "      <td>The project manager opened the meeting and rea...</td>\n",
              "      <td>0.523529</td>\n",
              "      <td>0.213018</td>\n",
              "      <td>0.294118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The project manager opened the meeting by goin...</td>\n",
              "      <td>The project manager opens the meeting by stati...</td>\n",
              "      <td>0.433526</td>\n",
              "      <td>0.087209</td>\n",
              "      <td>0.213873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>The project manager opened the meeting by tell...</td>\n",
              "      <td>The interface specialist and industrial design...</td>\n",
              "      <td>0.507463</td>\n",
              "      <td>0.187970</td>\n",
              "      <td>0.268657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>The project manager opened the meeting by goin...</td>\n",
              "      <td>The project manager recapped the decisions mad...</td>\n",
              "      <td>0.431095</td>\n",
              "      <td>0.120996</td>\n",
              "      <td>0.261484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>The project manager opened the meeting and int...</td>\n",
              "      <td>The Project Manager gave an introduction to th...</td>\n",
              "      <td>0.512821</td>\n",
              "      <td>0.181034</td>\n",
              "      <td>0.282051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>The project manager opened the meeting by goin...</td>\n",
              "      <td>The Project Manager reviewed the minutes from ...</td>\n",
              "      <td>0.492401</td>\n",
              "      <td>0.183486</td>\n",
              "      <td>0.285714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>The Project Manager opened the meeting by goin...</td>\n",
              "      <td>The project manager recapped the decisions mad...</td>\n",
              "      <td>0.378007</td>\n",
              "      <td>0.117647</td>\n",
              "      <td>0.226804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>The Project Manager opened the meeting by reca...</td>\n",
              "      <td>The project manager recapped the decisions mad...</td>\n",
              "      <td>0.477419</td>\n",
              "      <td>0.188312</td>\n",
              "      <td>0.290323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>The project manager opened the meeting by stat...</td>\n",
              "      <td>The User Interface Designer and the Industrial...</td>\n",
              "      <td>0.509554</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.235669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>The project manager opened the meeting by goin...</td>\n",
              "      <td>The project manager recapped the events and de...</td>\n",
              "      <td>0.577640</td>\n",
              "      <td>0.237500</td>\n",
              "      <td>0.347826</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>The project manager opened the meeting by goin...</td>\n",
              "      <td>The project manager opened the meeting and sta...</td>\n",
              "      <td>0.426966</td>\n",
              "      <td>0.158491</td>\n",
              "      <td>0.284644</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>The project manager opened the meeting by goin...</td>\n",
              "      <td>The Industrial Designer presented the function...</td>\n",
              "      <td>0.560694</td>\n",
              "      <td>0.238372</td>\n",
              "      <td>0.283237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>The project manager opened the meeting by goin...</td>\n",
              "      <td>The project manager recapped the decisions mad...</td>\n",
              "      <td>0.494545</td>\n",
              "      <td>0.219780</td>\n",
              "      <td>0.305455</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>The Project Manager opened the meeting by goin...</td>\n",
              "      <td>The Project Manager presented the project to t...</td>\n",
              "      <td>0.482014</td>\n",
              "      <td>0.188406</td>\n",
              "      <td>0.280576</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            generated  ...    rougeL\n",
              "0   The project manager opened the meeting by goin...  ...  0.200608\n",
              "1   The Project Manager opens the meeting. The Pro...  ...  0.245902\n",
              "2   The project manager opened the meeting by goin...  ...  0.308157\n",
              "3   The project manager opens the meeting by going...  ...  0.256944\n",
              "4   The Project Manager opened the meeting by stat...  ...  0.313725\n",
              "5   The project manager opened the meeting by goin...  ...  0.190202\n",
              "6   The Project Manager opened the meeting by reca...  ...  0.294118\n",
              "7   The project manager opened the meeting by goin...  ...  0.213873\n",
              "8   The project manager opened the meeting by tell...  ...  0.268657\n",
              "9   The project manager opened the meeting by goin...  ...  0.261484\n",
              "10  The project manager opened the meeting and int...  ...  0.282051\n",
              "11  The project manager opened the meeting by goin...  ...  0.285714\n",
              "12  The Project Manager opened the meeting by goin...  ...  0.226804\n",
              "13  The Project Manager opened the meeting by reca...  ...  0.290323\n",
              "14  The project manager opened the meeting by stat...  ...  0.235669\n",
              "15  The project manager opened the meeting by goin...  ...  0.347826\n",
              "16  The project manager opened the meeting by goin...  ...  0.284644\n",
              "17  The project manager opened the meeting by goin...  ...  0.283237\n",
              "18  The project manager opened the meeting by goin...  ...  0.305455\n",
              "19  The Project Manager opened the meeting by goin...  ...  0.280576\n",
              "\n",
              "[20 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU2r6JLjvhal"
      },
      "source": [
        "Final Results : (rouge1, rouge2, rougeL)  \n",
        "Test  47.28  17.25  26.40  \n",
        "Val  45.79  15.83  24.27"
      ]
    }
  ]
}